# Load Balancer Service

A Load Balancer service in the kubernetes helps exposes your application to the internet, means allowing people outside your kubernetes cluster to access it. Think you have given your app a public address so anyone can reach it.

 ```Load Balancer service, kubernetes cluster के अंदर created application को internet पर expose करती है, जिससे एक public Ip के through लोग application को access कर सकें|```

 Jab aapko chahiye ki aapka application internet se directly access ho, tab aapko LoadBalancer type use karna padta hai.

<br>

### Pehle Problem Samjho — Why Need a LoadBalancer service?

Kubernetes cluster ke andar jab hum koi web app ya API run karte hain, toh wo ek Pod ke form mein chalti hai.

Lekin:
- Pod ki IP Cluster ke bahar se access nahi hoti. Pod ki IP private hoti hai, aur sirf cluster ke andar se access ki ja sakti hai.
- Humara user to internet se aayega (ya cloud network se). Usko to access chahiye publicly — like ```https://mywebsite.com```.
- Internal ClusterIP aur NodePort se to external client access nahi kar sakta easily.

**Solution — Kubernetes LoadBalancer Service**

LoadBalancer service ek aisi service hoti hai jo cloud provider se ek public IP allocate karwata hai (jaise AWS, Azure, GCP), aur external clients ko allow karta hai ki wo directly Kubernetes application ko access kar sakein.

LoadBalancer service simply cloud main jake ek load balancer create kar deti hai jisse ek public ip mil jati hai aur user us public ip ka use karke application ko browser main access kar sakta hai.

<br>

### Important Point

LoadBalancer tabhi kaam karta hai jab tumhara cluster cloud environment me ho — jaise:
- EKS (AWS).
- AKS (Azure).
- GKE (Google Cloud).

Agar tum local Minikube ya kubeadm cluster pe ho, to LoadBalancer kaam nahi karega bina MetalLB jaise tool ke.

<br>

### How does a Load Balancer created in cloud.

**Step - 1: Tumne LoadBalancer Service YAML create karke YAML Apply Kiya**:

Example:
```
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  type: LoadBalancer
  selector:
    app: myapp
  ports:
    - port: 80
      targetPort: 8080
```
- Jab tum YAML apply karte ho to kubectl tumhara manifest API Server ko bhejta hai.
- API Server validate karta hai:
  - Syntax theek hai?
  - Required fields present hain?
- Phir service object ko etcd database me store karta hai.

Important Point:
```
spec:
  type: LoadBalancer
```
- ye field API server dekhta hai aur ```type``` ko ```LoadBalancer``` mark karta hai, jo baad me trigger karega Cloud integration ko.


**Step - 2: Kubernetes Cloud Controller Manager (CCM) Trigger Hota Hai**:

- CCM (Cloud Controller Manager) ek Kubernetes internal component hota hai jo control plane main hota hai.
- Ye har major cloud provider (AWS, Azure, GCP) ke liye alag hota hai.
- Sirf tab active hota hai jab tum Kubernetes cluster ko kisi cloud provider par chala rahe ho (AWS, Azure, GCP, etc.).
- Ye api server ko watch loop main dekhta hai ki kya cluster me koi aisa service create hua jiska type ```LoadBalancer``` hai.
- Jaise hi aisa service dikhta hai, ye cloud ke REST API ya SDK se baat karta hai:
  - Public Load Balancer banana.
  - Nodes ke IP address aur NodePort use karke listener rules set karta hai.
  - DNS name ya public IP assign karta hai.
 
Output:
- Ek cloud-level Load Balancer ready ho jaata hai.
- Uska public IP/DNS naam mil jaata hai.

<br>
<br>

### How does Load Balancer sends traffic to pod.

Ab dekhte hain ki jab user load balancer ki public ip se application ko access karta hai to traffic pod tak kaise pahunchta hai.

**Step-1: User Sends Request to Public IP**:
- Browser se user ne ```http://<LoadBalancer-Public-IP>:80``` pe request bheji.
- Ye request pehle Cloud Load Balancer tak jaati hai.

**Step-2: Cloud Load Balancer Forwards to Kubernetes NodePort**:
- Load Balancer randomly ya round-robin basis pe ek node select karta hai (from the available pool of worker nodes).
- Us selected Node ke ```NodeIP:NodePort``` (e.g. 192.168.1.12:31234) pe request bhejta hai.

**Step-3: NodePort forwards the request to cluster ip using Kube Proxy**:
- Har worker node par ek ```kube-proxy``` hota hai. Ye kube-proxy worker node ke kernal pe ```iptables/ipvs``` rules bana deta hai.
- Aur un rules ke andar likha hota hai:
  - ```"Agar traffic Node ke port 31234 pe aaya, toh use ClusterIP (10.96.0.10) ke port 80 pe forward karo aur cluster ip ki selector list se pod select karo."```.
 
Matlab ```kube-proxy``` ke paas cluster-ip ki list hoti hai aur cluster-ip ke selector ki detail bhi hoti hai jisse kube-proxy pod ko select karta hai.

Matlab yha ```kube-proxy``` cluster-ip ke selector ki help se ye decide karta hai ki konse pod par request bheju.

Jaise hum service yaml main selector ka use karke btate hain ki konse pod se ye service attach hogi, to ye hi list kube-proxy ke paas hoti hai.

Isi list ko use karke use karke ```kube-proxy``` pod select karta hai. Fir request ko forward hoti hai selected pod ip pe.

Request pehle NodePort pe aati hai, fir kube-proxy ke iptables/ipvs rules ye decide karte hain ki us request ko ClusterIP pe redirect karna hai, aur us ClusterIP ke selector ke through kis pod pe bhejna hai.

**Step-4: Kube-proxy forward the traffic to pod**:

Ab ```kube-proxy``` traffic ko pod par forward karta hai.

Agar Pod same Node pe nahi hai, to:
- Linux kernel ke routing table se packet cross-node jaata hai ```node-B``` pe.
- Yaha CNI plugin (flannel, calico, weave etc.) is packet ko virtual ethernet interface ke through pod tak le jaata hai.
- Agar Pod same Node pe hota, to directly veth bridge se pod mil jaata.

**Step-5: Pod ke andar container pe request aati hai**:

Container par request jati hai aur humko same path se hote hue response milta hai aur web aap application browser pe dekh paate hain.



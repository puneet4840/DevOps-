# Kubernetes mein OOM Error (Out Of Memory) Kya Hota Hai?

<br>

**Sabse Pehle: OOM ka matlab kya?**:

OOM = Out Of Memory.

Yahan memory ka matlab hai RAM.

<br>

Kubernetes mein **OOMKilled** (Out Of Memory) ek aisi situation hai jo tab aati hai jab koi Container apni allotted memory limit se zyada consume karne lagta hai, ya phir node ke paas bilkul memory bachi hi nahi hoti.

OOM Error ke 2 reasons hote hain:
- Jab koi container apni set limit se jyada memory use karne lagta hai tab.
- Jab Node ki memory exhaust yaani bilkul khatam hoti hai tab.

<br>
<br>

### OOMKilled Kyun Hota Hai?

Kubernetes mein OOM error ke do main types hote hain:

<br>

**1 - Container ki Limit Reach Ho Jana**:

Jab aap apne Pod ki YAML file mein ```resources.limits.memory``` define karte ho, to Kubernetes us container par ek sakth nazar rakhta hai.
- Agar aapka application memory jyada use kar raha hai ya sudden load ki wajah se limit cross karta hai, to Linux Kernel us process ko terminate kar deta hai.
- Iska error code hota hai: Exit Code 137.
- Tab ye OOM Killed error aata hai.


Detail Mein Samjho:

Kubernetes mein har container ke paas Linux ka ek feature hota hai jise Cgroups (Control Groups) kehte hain. Jab aap YAML mein ```limits.memory: "512Mi"``` likhte ho, to Kubernetes backend mein Linux kernel ko bol deta hai ki "Bhai, is process ko 512MB se ek byte bhi upar mat dena."

Jaise hi application ko zyada data process karna padta hai aur wo 513MB maangta hai, Linux ka OOM Killer turant active ho jata hai aur us process (container) ko 'Kill' kar deta hai taaki wo baaki system ko disturb na kare.


Real-World Example Se Samjhte Hain:

Maano tumhare paas ek Python Flask application hai jo images process karti hai.

Scenario:
- Tumne Pod ki limit set ki hai 512MB.
- Normal time par app 200MB RAM use kar raha hai. Sab badhiya chal raha hai.
- Suddenly, 100 users ne ek saath 4K images upload kar di.
- App ko unhe process karne ke liye 600MB RAM ki zaroorat padi.
- Jaise hi memory usage 512MB ko touch karke cross karne ki koshish karegi, Linux ka OOM Killer active ho jayega.
- Tumhara Pod "```CrashLoopBackOff```" status mein chala jayega aur kubectl get pods karne par OOMKilled dikhayega.

<br>
<br>

**2 - Node Memory Exhaust Ho Jana**:

Jab worker node ki RAM full ho jati hai to aise mein Kubelet (node ka manager) priority ke basis par kisi pod ko "evict" matlab node se remove kar deta hai taaki node crash na ho.

To us time par Node ka status check karoge to "MemoryPressure" error dikhayega dikhayega.

Detail Mein Samjho:

Har Worker Node ki ek capacity hoti hai (maano 8GB RAM). Is RAM mein se kuch hissa Operating System (Ubuntu/Amazon Linux) leta hai, kuch Kubelet leta hai, aur baaki Pods ke liye hota hai.
Kayi baar hum pods par Limits lagana bhool jate hain (Best Practice nahi hai, par log karte hain). Aise mein agar ek pod ke uper load ki wajah se saari RAM khane lage, to Node ke paas OS chalane ke liye bhi RAM nahi bachti. Isse pura Node crash ho sakta hai. Is crash se bachne ke liye, Kubelet ek "Eviction" process shuru karta hai.


Real-World Example Se Samjhte Hain:

Maano ek Node hai jiski total RAM 8GB hai.

Scenario:
- Pod A (Database): Request 2GB, Limit 4GB.
- Pod B (Python Script): Is par koi Limit nahi lagayi gayi (Unbounded).
- Problem: Python script mein ek "Memory Leak" hai (wo purani RAM release nahi kar raha). Dhire-dhire Python script 1GB -> 3GB -> 6GB RAM khane lagta hai.
- Action: Ab Node ki total RAM (8GB) khatam hone wali hai. OS khatre mein hai. Kubelet dekhega ki sabse zyada RAM kaun kha raha hai aur kiske pas "Guaranteed" status nahi hai.
- Result: Kubelet Pod B ko terminate kar dega (OOMKilled) ya phir Pod A ko kisi aur node par shift karne ki koshish karega. Is case mein aksar error "Node-pressure Eviction" dikhayi deta hai.



Matlab dono cases mein pod ko evict hona padta hai. Ye error dekhne ke liye humko pod ke logs check karne padte hain aur node ka status check karna padta hai ki error aay kis wajah se hai.

<br>
<br>

### Dono Mein Difference Kya Hai? (Quick Summary Table)

|Feature|Pod Limit OOM|Node Memory OOM|
|:----|:----|:----|
|Kaun Maarta Hai?|Linux Kernel (Cgroups)|Kubelet (Eviction Manager)|
|Kyun Maarta Hai?|Pod ne apni "Limit" cross ki.|Node ki total RAM khatam ho gayi.|
|Monitoring|```kubectl describe pod``` mein "OOMKilled" dikhega.|Node status "MemoryPressure" dikhayega.|
|Fix Kaise Kare?|Pod ki limits badhao ya code optimize karo.|Bade Nodes use karo ya Pods par limits lagao.|

# Pod Disruption Budget Error

Jab mai ek project mein QA Enviornment ka AKS cluster upgrade kar rha tha to cluster upgrade ke time par ek error aa rha tha, aur cluster upgrade nahi ho rha tha. To is document mein hum vo hi dekhenge ki error kya tha aur kyu aa rha tha.

<br>
<br>

### Pehle samjhte hain — AKS cluster upgrade hota kaise hai?

Jab tum AKS cluster upgrade karte ho (for example, ```1.28``` → ```1.29```), to Azure AKS rolling upgrade mechanism follow karta hai.

Kya hota hai background me:
- AKS control plane pehle upgrade hota hai (API Server, Controller, Scheduler).
- Phir har node pool me ek ek worker node ko drain karke recreate kiya jaata hai new version ke saath.
- “Draining node” ka matlab hai:
  - Node pe jo pods chal rahe hain unhe safely evict (remove) karna.
  - Fir node cordon ho jata hai (taaki naye pods uspar na jaayein matlab naye pods us node pe schdule na ho).
  - Jab sab pods evict ho jaate hain → node delete ho jata hai → new node ban jaata hai new version me.
 
<br>
<br>

### Error kaha aaya tha?

Upgrade fail hua yahan:
```
Error: (UpgradeFailed) Drain node aks-nodepool3-14710108-vmss000000 failed
Reason: Evict blocked by conflicting disruption budgets.
Pod: metrics-server-879ddff78-wrw6b
```

Yani AKS ne ek worker node drain karne ki koshish ki, lekin ek pod (```metrics-server```) **evict(remove) nahi ho paaya**, kyunki us pod ke saath ek **Pod Disruption Budget(PDB)** associated tha to Pod Disruption Budget (PDB) ne pod ```metrics server``` pod evict allow nahi kiya.

<br>
<br>

### “Pod Disruption Budget” kya hota hai?

**Pod Disruption Budget (PDB)** kubernetes ka ek resource hota hai jo batata hai ki itne number of pods hamesha run hote rahenge cluster mein.

Kubernetes me Pod Disruption Budget (PDB) ek protection mechanism hai jo ensure karta hai ki application ke kuch pods hamesha available rahein, chahe cluster me maintenance ya upgrade chal raha ho.

Matlab — “main tumhe kuch pods delete karne dunga, lekin itne se kam pods agar bache, to delete nahi hone dunga.”

Example:
```
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: metrics-server-pdb
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: metrics-server
```

Yahan likha hai:
- Minimum 1 pod hamesha available rehna chahiye.
- Agar 1 hi pod hai aur use drain ke time delete karne ki koshish ki jaati hai → Eviction block ho jaata hai.

<br>
<br>

### Toh hua kya tha AKS upgrade ke dauran?

Jab AKS upgrade chalu hua:
- AKS ne ek node choose kiya: ```aks-nodepool3-14710108-vmss000000```.
- Us node pe ```metrics-server``` pod chal raha tha.
- AKS upgrade process ne node drain karne ke liye API call ki:
```
kubectl drain aks-nodepool3-14710108-vmss000000 --ignore-daemonsets
```
- Drain process ne ```metrics-server``` pod evict karne ki koshish ki, par ```kube-apiserver``` ne bola ki pod evict nhi kar sakte:
```
Cannot evict pod "metrics-server-879ddff78-wrw6b": it would violate the pod's disruption budget.
```
- Kyonki PDB me likha tha:
```
minAvailable: 1
```
aur cluster me total ```metrics-server``` pods bhi sirf 1 the → Eviction block ho gaya.

AKS ke upgrade controller ko “node drain failed” mila → UpgradeFailed error trigger ho gaya.

<br>
<br>

### Error kyun hota hai — deep mechanism

Kubernetes ```drain``` command har pod ko eviction API ke through remove karta hai.

Eviction API flow kuch aisa hota hai:
```
kubectl drain → API Server → Admission Controller → PDB Validation
```
PDB validation dekhta hai:
- Kitne pods abhi running hain.
- Kitne ```minAvailable``` defined hain.
- Agar eviction ke baad available pods < minAvailable → block eviction.

So in your case:

| Setting                           | Actual Value   |
| --------------------------------- | -------------- |
| Total running metrics-server pods | 1              |
| minAvailable in PDB               | 1              |
| After eviction, pods left         | 0              |
| ✅ Rule Check                      | ❌ FAIL (0 < 1) |

Hence — Eviction blocked ✅

Node drain failed ✅

Cluster upgrade stopped ❌

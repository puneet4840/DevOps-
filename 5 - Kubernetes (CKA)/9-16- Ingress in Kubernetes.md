# Ingress in Kubernetes

Ingress is a resource in kubernetes which is used to manage external access to service within a kubernetes cluster. 

```Ingress kubernetes ‡§ï‡§æ ‡§è‡§ï resource ‡§π‡•à ‡§ú‡•ã external traffic ‡§ï‡•ã kubernetes ‡§ï‡•Ä services ‡§§‡§ï ‡§™‡§π‡•Å‡§ö‡§§‡§æ ‡§π‡•à ‡§Æ‡§§‡§≤‡§¨ application ‡§ï‡•ã outside world ‡§ï‡•á ‡§≤‡§ø‡§è expose ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§Æ‡§§‡§≤‡§¨ users ingress ‡§ï‡•á through kubernetes ‡§™‡§∞ deployed application ‡§ï‡•ã internet ‡§ï‡•á through access ‡§ï‡§∞ ‡§™‡§æ‡§è‡§Ç‡§ó‡•á|```

In a Kubernetes cluster, applications often need to be accessed from outside the cluster, such as a website that users access via the internet. Ingress is a Kubernetes resource designed to expose such services to external clients, typically via HTTP or HTTPS.

<br>

Kubernetes mein agar humein apne cluster ke andar chal rahi applications ko bahar se access karna hota hai, toh humein ek mechanism chahiye hota hai jo external traffic (jaise user ka browser ya API client) ko correct pod/service tak le jaye.

By default, pods ek cluster-internal IP par run karte hain, jo directly bahar se accessible nahi hota. Iske liye hum Service banate hain (ClusterIP, NodePort, LoadBalancer). Lekin agar tumhare paas multiple microservices hain aur tum chahte ho ki ek hi domain (jaise myapp.com) ke andar alag-alag paths/hostnames ke through traffic route ho, toh waha Ingress use hota hai.

Ingress = ek tarah ka Smart HTTP/HTTPS router jo request ko route karta hai based on hostname aur path.

Example:
- ```myapp.com/api``` ‚Üí backend service-1
- ```myapp.com/web``` ‚Üí backend service-2
- ```shop.myapp.com``` ‚Üí backend service-3

<br>

### Ingress Kyu Zaroori Hai? (Use Cases)

Socho tumhare paas ek ecommerce app hai jisme multiple microservices hain:
- frontend-service (React/Angular UI).
- catalog-service (product list API).
- order-service (order API).
- payment-service (payment API).

Agar tum har ek service ko NodePort/LoadBalancer banate ho toh har service ke liye alag public IP / port manage karna padega. Ye complex ho jaata hai.

Ingress ke saath:
- Tum bas ek hi LoadBalancer use karte ho.
- Baaki sab traffic routing rules Ingress handle karta hai.
- SSL/TLS termination easily ho jata hai (HTTPS setup).
- Host-based aur path-based routing dono milta hai.

<br>


### Why do we need Ingress?

```‡§π‡§Æ‡§ï‡•ã ‡§™‡§§‡§æ ‡§π‡•à ‡§ï‡•Ä ‡§ú‡§¨ appllication ‡§ï‡•ã kubernetes cluster ‡§™‡§∞ deploy ‡§ï‡§∞‡§§‡•á ‡§π‡•à ‡§§‡•ã ‡§â‡§∏ application ‡§ï‡•ã access ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ service ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à‡§Ç ‡§ñ‡§æ‡§∏‡§ï‡§∞ application ‡§ï‡•ã internet ‡§ï‡§∞ access ‡§ï‡§∞‡§®‡§æ ‡§π‡•ã‡§§‡§æ ‡§π‡•à ‡§§‡•ã Load Balancer type ‡§ï‡•Ä service ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à| ‡§§‡•ã ‡§Ø‡•á Load Balancer type ‡§ï‡•Ä service cloud ‡§™‡§∞ ‡§è‡§ï Load Balancer create ‡§ï‡§∞ ‡§¶‡•á‡§§‡•Ä ‡§π‡•à ‡§ú‡§ø‡§∏‡§∏‡•á Load Balancer ‡§™‡§∞ request ‡§≠‡•á‡§ú‡§ï‡§∞ application ‡§ï‡•ã access ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç| ‡§ú‡§¨ ‡§Ø‡§π‡§æ‡§Å ‡§§‡§ï ‡§∏‡§¨ ‡§ö‡•Ä‡•õ ‡§†‡•Ä‡§ï ‡§ö‡§≤ ‡§∞‡§π‡•Ä ‡§•‡•Ä ‡§§‡•ã ‡§Ø‡•á Ingree ‡§®‡§æ‡§Æ ‡§ï‡•Ä ‡§ö‡•Ä‡•õ ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§Ü‡§Ø‡•Ä|```

```‡§ï‡•ç‡§Ø‡•Å‡§ï‡•Ä kubernetes ‡§Æ‡•à‡§Ç service ‡§ï‡•Ä ‡§ï‡•Å‡§õ disadvantages ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡§Ç ‡§ú‡§ø‡§∏‡§ï‡•ã ‡§π‡§Æ Ingress ‡§∏‡•á solve ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡•à‡§∏‡•á ‡§ï‡•Ä: ```

- ```Service ‡§ï‡•ã ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§π‡§Æ cloud clusters ‡§™‡§∞ ‡§π‡•Ä use ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§Æ‡§§‡§≤‡§¨ cloud ‡§Æ‡•à‡§Ç ‡§ú‡§¨ ‡§π‡§Æ cluster ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à ‡§ú‡•à‡§∏‡•á AKS, EKS, GKE ‡§á‡§® clusters ‡§™‡§∞ ‡§π‡•Ä Load Balancer type ‡§∏‡§∞‡•ç‡§µ‡§ø‡§∏ ‡§ï‡§∞ use ‡§π‡•ã‡§§‡§æ ‡§π‡•à ‡§ï‡•ç‡§Ø‡•Å‡§ï‡•Ä ‡§ú‡§¨ service Load Balancer type ‡§ï‡•Ä ‡§π‡•ã‡§§‡•Ä ‡§π‡•à ‡§§‡•ã service ‡§ï‡•ã Load Balancer cloud ‡§π‡•Ä provide ‡§ï‡§∞‡§§‡§æ ‡§π‡•à| ‡§á‡§∏‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§π‡•à ‡§ï‡•Ä Load Balancer type ‡§ï‡•Ä service ‡§∏‡§ø‡§∞‡•ç‡§´ cloud dependent ‡§π‡•ã‡§§‡•Ä ‡§π‡•à ‡§ú‡•ã ‡§è‡§ï disadvantage ‡§π‡•à|```

- ```‡§Ö‡§ó‡§∞ Kubernetes Cluster ‡§Æ‡•à‡§Ç ‡§π‡§Æ‡§®‡•á ‡§è‡§ï web application deploy ‡§ï‡•Ä, ‡§§‡•ã ‡§â‡§∏ web application ‡§ï‡•ã internet ‡§™‡§∞ access ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è load balancer type ‡§ï‡•Ä service ‡§¨‡§®‡§æ‡§®‡•Ä ‡§™‡•ú‡•á‡§ó‡•Ä ‡§ú‡§ø‡§∏‡§∏‡•á ‡§è‡§ï load balancer web application ‡§ï‡•á ‡§≤‡§ø‡§è cloud ‡§™‡§∞ create ‡§π‡•ã ‡§ú‡§æ‡§Ø‡•á‡§ó‡§æ| Suppose ‡§Ö‡§ó‡§∞ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§™‡§æ‡§∏ ‡§ê‡§∏‡•Ä 10 web applications ‡§π‡•à ‡§î‡§∞ ‡§µ‡•ã ‡§π‡§Æ kubernetes ‡§™‡§∞ deploy ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§§‡•ã ‡§â‡§® ‡§∏‡§≠‡•Ä ‡§µ‡•á‡§¨ ‡§è‡§™‡•ç‡§≤‡•Ä‡§ï‡•á‡§∂‡§® ‡§ï‡•ã ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§™‡§∞ ‡§è‡§ï‡•ç‡§∏‡•á‡§∏ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó load balancers ‡§ï‡•ç‡§∞‡§ø‡§è‡§ü ‡§ï‡§∞‡§®‡•á ‡§π‡•ã‡§Ç‡§ó‡•á ‡§Æ‡§§‡§≤‡§¨ 10 web applications ‡§ï‡•á ‡§≤‡§ø‡§è 10 load balancers create ‡§π‡•ã‡§Ç‡§ó‡•á ‡§ú‡§ø‡§∏‡§∏‡•á ‡§π‡•ã‡§ó‡§æ ‡§Ø‡•á ‡§ï‡•Ä ‡§á‡§§‡§®‡•á ‡§∏‡§æ‡§∞‡•á load balancers ‡§ï‡•Ä cost ‡§π‡§Æ‡§ï‡•ã pay ‡§ï‡§∞‡§®‡•Ä ‡§™‡•ú‡•á‡§ó‡•Ä ‡§î‡§∞ ‡§ê‡§∏‡§æ scenario efficient ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à ‡§§‡•ã ‡§π‡§∞ application ‡§ï‡•ã internet ‡§™‡§∞ expose ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è load balancer ‡§ï‡§æ use ‡§® ‡§ï‡§∞‡§ï‡•á ‡§π‡§Æ Ingress resource ‡§ï‡§æ use ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç|```.

<br>
<br>

Kubernetes provides several ways to expose services, including:

- **ClusterIP**: Default type, makes the service only accessible within the cluster.
- **NodePort**: Exposes the service on a static port on each node, allowing access from outside the cluster.
- **LoadBalance**r: Allocates a cloud provider‚Äôs load balancer, exposing the service externally.

Each of these has its limitations:

- **NodePort**: Uses static ports and can expose a limited number of services due to port limits.
- **LoadBalancer**: Good for a single service but can be inefficient when you need to expose multiple services.

**Ingress provides**:

- **Routing** to direct external requests to the appropriate services.
- **Host-based or path-based** routing to control which traffic goes to which application.
- **TLS/SSL** support to secure applications with HTTPS.

Ingress offers a more centralized and scalable way to manage access to multiple services, especially for HTTP/HTTPS traffic. You can:

- Manage all routing rules in one place (It means we can forward incoming request to multiple services using only one ingress resource).
- Configure HTTPS/TLS centrally.
- Route based on paths and hostnames, allowing multiple services to share a single IP.

<br>

<img src="https://drive.google.com/uc?export=view&id=1OI23Rgntu7TK5QnTBKZIBzBIxI1lMIaE">

<br>
<br>

### Working of Ingress Example

- Ek nginx app hai aur ek notes app hai.
- Dono sirf ClusterIP service ke saath expose kiye gaye hain (matlab cluster ke andar hi accessible hain, bahar se nahi).
- Requirement: Dono ko ek hi IP se access karna hai, jaise:
  - ```http://<same-ip>/nginx``` ‚Üí nginx app.
  - ```http://<same-ip>/notes``` ‚Üí notes app.
 
Yehi kaam Ingress karta hai.

**Traditional Approach (NodePort / LoadBalancer)**:
- Agar tum NodePort/LB service banate toh har ek app ke liye alag port/IP lagti.
- Har app ke liye alag IP/port manage karna padta ‚Üí messy & costly.

**Ingress Approach**:
- Step 1: Ingress Controller Install Karo:
  - Ingress tabhi kaam karta hai jab ek Ingress Controller cluster me run ho (jaise NGINX Ingress Controller).
  - Ye ek pod/deployment hota hai jo sab external traffic receive karta hai.
    
- Step 2: Applications Deploy Karo:
  - Har app (nginx + notes) ko Deployment aur ClusterIP service ke saath deploy karo.
  - Example:
    - nginx-service (port 80 ‚Üí nginx pods).
    - notes-service (port 80 ‚Üí notes pods).
  - Dono sirf cluster ke andar available rahenge.

- Step 3: Ingress Resource Banao:
  - Ek Ingress YAML likho jisme path-based routing rules ho.
  - Ye Ingress Controller ko bata dega ki kaunsi request kahan forward karni hai.
 
- Step 4: Access From Outside:
  - Ingress Controller ek LoadBalancer/NodePort service ke saath expose hota hai.
  - Us IP/domain ko use karke tumhar apps accessible ho jaate hain:
    - ```http://<Ingress-IP>/nginx``` ‚Üí nginx app.
    - ```http://<Ingress-IP>/notes``` ‚Üí notes app.

<br>
<br>

### Components of Ingress

Ingress ek API object hai jo cluster ke andar chalne wale applications (services/pods) ko bahar se HTTP/HTTPS traffic ke liye expose karta hai.

Iske andar kuch core components hote hain jo milke kaam karte hain.

- Ingress Resource (YAML Congiguration).
- Ingress Controller (Pod and Service).
- Ingress Class.
- Backend Services (ClusterIP/NodePort/LoadBalancer).

<br>

**1 - Ingress Resource (YAML Configuration)**:

Ye ek YAML configuration object hai jo define karta hai ki traffic ko kaise route karna hai. Actual main ye ek yaml file hoti hai jisme hum likhte hain ki request ko kaise aur kaha route karna hai.

```Ingress resource ingress ‡§ï‡•ã define ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï Yaml file ‡§π‡•ã‡§§‡•Ä ‡§π‡•à ‡§ú‡§ø‡§∏‡§Æ‡•á ‡§Æ‡•à‡§Ç ‡§π‡§Æ define ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡•Ä ‡§ú‡§¨ ingress ‡§∏‡•á kubernetes service ‡§™‡§∞ external request ‡§Ü‡§è‡§ó‡•Ä ‡§§‡•ã ‡§â‡§∏ request ‡§ï‡•ã ‡§ï‡•ã‡§®‡§∏‡•Ä kubernetes service ‡§™‡§∞ transfer ‡§ï‡§∞‡§®‡§æ ‡§π‡•à|```

Isme hum define karte hain:
- Hostnames (domain names) ‚Üí jaise app.example.com
- Paths (URL routes) ‚Üí jaise /api, /shop, /blog
- Backend services ‚Üí kis service ko request bhejni hai

Ye sirf ek rule set hai. Ye khud se traffic handle nahi karta. Traffic ko handle karne ka kaam Ingress Controller karega.

Example of Ingress Resource:
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-ingress
spec:
  rules:
  - host: shop.example.com
    http:
      paths:
      - path: /cart
        pathType: Prefix
        backend:
          service:
            name: cart-service
            port:
              number: 80
      - path: /order
        pathType: Prefix
        backend:
          service:
            name: order-service
            port:
              number: 80
```
<br>

Example of Ingress Resource:
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: example-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  tls:
  - hosts:
      - myapp.example.com
    secretName: myapp-tls
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /app1
        pathType: Prefix
        backend:
          service:
            name: app1-service
            port:
              number: 80
```

Explaination:

- apiVersion and kind:
  - apiVersion: Specifies the version of the Kubernetes API used for this resource. For Ingress resources, this is typically networking.k8s.io/v1.
  - kind: Defines the type of Kubernetes resource, which is Ingress in this case.
 
  These fields tell Kubernetes that we are creating an Ingress resource according to the networking.k8s.io/v1 API.

- metadata:
  - name: The name of the Ingress resource, which should be unique within the namespace. In this case, it‚Äôs named example-ingress.
  - namespace: Specifies the Kubernetes namespace where this Ingress resource will be created. By default, it‚Äôs set to default, but you could use other namespaces if desired.
 
- annotations:
  - Annotations provide additional options for configuring the behavior of the Ingress Controller. Here, we have:
    - nginx.ingress.kubernetes.io/rewrite-target: /: This annotation is specific to the NGINX Ingress Controller. It rewrites the URL path for requests that match a certain path. For instance, if a request is made to /app1, the controller will rewrite the path to / before forwarding it to the service. This can be helpful if the backend service is expecting a specific path format.

  Note: Different Ingress Controllers support different annotations, so the available options depend on the Ingress Controller you‚Äôre using (e.g., NGINX, Traefik, or HAProxy)

- spec:
  - The spec section is where we define the actual routing rules, TLS settings, and other configurations for the Ingress resource.
 
  - tls:
    - Specifies the TLS (Transport Layer Security) settings to enable HTTPS for specific hosts.
      - hosts: A list of hostnames (domains) that will use TLS. In this example, myapp.example.com is specified.
      - secretName: The name of a Kubernetes Secret that contains the TLS certificate and key. This Secret must be created beforehand and should include the certificate and private key for the specified host(s).
     
    - This section configures HTTPS for the myapp.example.com domain. When a client requests https://myapp.example.com, the Ingress Controller will use the specified TLS certificate from myapp-tls.

  - rules:

    The rules section defines the main routing rules for the Ingress resource. Each rule specifies how traffic should be directed based on the requested host and path.

    - host:
      - host: The hostname (domain) that the rule applies to, e.g., myapp.example.com. Only requests matching this hostname will be processed by this rule. If the request doesn‚Äôt match the hostname, the Ingress Controller will ignore it.

        In our example, the rules are defined for the myapp.example.com host. Requests to this domain are routed based on the paths defined in http.

    - http:
      - http: Defines HTTP-specific routing rules for the host. Within http, you can define multiple paths, each with its own backend service.


    - paths:
      - paths: A list of path rules. Each path rule consists of:
        - path: Specifies the URL path for which this rule applies. For example, /app1 or /app2. This path is matched against the incoming request‚Äôs URL.
       
        - pathType: Defines how the path should be matched. The main options are:
          - Prefix: Matches requests where the URL path begins with the specified path. For example, if path: /app1 and pathType: Prefix, requests to /app1, /app1/page, etc., will match this rule.
          - Exact: Matches the path exactly. So path: /app1 with pathType: Exact would only match requests to /app1, not /app1/page.
          - ImplementationSpecific: Allows the Ingress Controller to determine how paths are matched, which might vary by controller.

    - backend:
      - backend: Defines the target service and port where matching requests should be routed.
        - service.name: Specifies the name of the service to forward traffic to (e.g., app1-service).
        - service.port.number: The port on the service where traffic should be directed (e.g., 80).

  Exmple Path rule:

  ```
    - path: /app1
      pathType: Prefix
      backend:
        service:
          name: app1-service
          port:
            number: 80
  ```

  In this example:
  - Requests to myapp.example.com/app1 will be routed to the app1-service service on port 80.
  - Since pathType is Prefix, requests to /app1/page will also match this rule.


<br>

**2 - Ingress Controller**:

Ingress Controller ek software component (controller pod) hai jo Kubernetes ke andar run hota hai aur Ingress Resources (rules) ko implement karta hai.
- Kubernetes sirf ek Ingress API object deta hai, matlab ek yaml configuration deta hai (rules likhne ke liye).
- Lekin vo rules tab tak kaam nahi karenge jab tak ek Ingress Controller na ho jo unko implement kare.

Kubernetes ek built-in Ingress Controller provide nahi karta. Tumhe apna controller install karna padta hai.

Kuch popular Ingress Controllers hain:
- NGINX Ingress Controller ‚Üí sabse zyada use hota hai, open-source aur stable.
- HAProxy Ingress Controller ‚Üí high performance.
- Traefik ‚Üí simple, modern, auto-discovery.
- Envoy/Istio Gateway ‚Üí service mesh world me
- Cloud Specific:
  - AWS ALB Ingress Controller
  - Azure Application Gateway Ingress Controller
  - GCP Load Balancer Controller

Tumko ingress use karne ke liye alag se ingres ko setup karna hoga, jisme ingres controller setup hota hai.

Jab hum Ingress Controller (jaise NGINX Ingress Controller) deploy karte hain, vo ek Deployment/DaemonSet ke form mein pods run karta hai.

Lekin pods ke paas apna public IP nahi hota. Pods to cluster ke andar internal IPs pe chalte hain.

Client ko agar bahar se access karna hai (internet se), to hume Ingress Controller ko expose karna padta hai.

Yahan aati hai Service ki zarurat.

Ingress Controller Service:
- Jab hum Ingress Controller install karte hain (Helm/YAML se), uske saath ek Service create hoti hai jo Ingress Controller ke pods ko expose karti hai.

Ye service kuch is tarah hoti hai:
```
apiVersion: v1
kind: Service
metadata:
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  type: LoadBalancer
  ports:
  - name: http
    port: 80
    targetPort: http
  - name: https
    port: 443
    targetPort: https
  selector:
    app.kubernetes.io/name: ingress-nginx
```
- ```type: LoadBalancer``` ‚Üí Yeh batata hai ki Kubernetes cloud provider ko bolega ek external load balancer allocate karo.
- ```ports: 80, 443``` ‚Üí Yehi ports se client traffic aayega.
- ```selector``` ‚Üí Yeh service Ingress Controller pods ko select karegi.

Agar tum Cloud Provider (AWS, Azure, GCP) pe Kubernetes cluster main ho:
- Jaise hi Service ```type=LoadBalancer``` banti hai, cloud provider automatically ek external Load Balancer create kar deta hai.
- Is load balancer ko ek public IP assign hoti hai.
- Aur ye hi public ip ingres controller ko assign ho jati hai.

Iska matlab hai ki Ingres Controller ko jab hum apne cluster main setup karte hain to sabse pehle ek ingres controller pod create hota hai, us pod ko expose karne ke liye ek load balancer type ki service create hoti hai, fir vo service cloud main ek Load Balancer create karti hai aur load balancer ki public ip ingres controller pod ko assign ho jati hai.

Isi ip ko use karke hum applications ko access karte hain.

Agar tum KIND ya miki-kube cluster use kar rahe ho to controller ko nodePort ki ip assign hoti hai.

Flow with LoadBalancer IP:
- Tumne Ingress Controller Service type=LoadBalancer banayi.
- Azure/AWS automatically ek load balancer banata hai aur usko ek IP deta hai, maan lo:
  ```
  20.55.88.10
  ```
- Ab client jab bhi http://20.55.88.10 ya tumhara domain (jo is IP pe point kiya hai) access karega ‚Üí
  - Request pehle Cloud Load Balancer pe aayegi.
  - Cloud Load Balancer request ko cluster ke ek node ke NodePort pe bhejega.
  - Wahan se Ingres Service ‚Üí Ingress Controller pod ko forward karegi.
  - Ingress Controller apne ingres rules ke hisaab se backend services ko forward karega.

<br>

**3 - Ingress Class**:
- Ingress class ek selector/identifier hai jo batata hai ki kaunsa Ingress Controller is Ingress ko handle karega.
- Ek cluster me multiple Ingress Controllers ho sakte hain. Example:
  - ```nginx``` Ingress Controller.
  - ```traefik``` Ingress Controller.

Agar apke cluster main multiple ingres controller installed hain to apko ingress claas main mention karna hoga ki konsa ingress controller ingress resource ko handle karega, sirf ye hi use hota hai ingress class ka.

Example:
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: api-ingress
spec:
  ingressClassName: nginx
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 80
```
- Yahan ```ingressClassName: nginx``` ka matlab hai ki sirf NGINX Ingress Controller isko process karega.

<br>

**4 - Backend Services (ClusterIP/NodePort/LoadBalancer)**:
- Pods ko expose karne ke liye jo service created hoti hain, jaise nginx pod ko expose karna hai uske liye hum clusterIp type ki service bana denge, to isi ko hum bakend services bolte hain.
- Ingress ka ultimate kaam hai request ko ek Kubernetes Service tak bhejna.
- Service ka type mostly ClusterIP hota hai (kyunki Ingress controller already LoadBalancer ya NodePort ke through expose hota hai).
- Service ke peeche Pods hote hain jo actual application run kar rahe hote hain.

Example Flow:
- Ingress rule ‚Üí /order ‚Üí order-service (ClusterIP: 10.96.23.15) ‚Üí pods of order-service.

<br>
<br>

### How to Set Up an Ingress Controller (Example: NGINX Ingress Controller)

Setting up an Ingress Controller involves deploying it within your cluster, configuring the necessary services, and then defining Ingress resources to route traffic to services.

- **Install the NGINX Ingress Controller**:

  You can install the NGINX Ingress Controller using kubectl and a YAML file provided by the Kubernetes project. This file contains the deployment and service specifications for the NGINX Ingress Controller.

  ```
    kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
  ```

  This deployment sets up the NGINX Ingress Controller within your cluster. By default, it creates a LoadBalancer service to expose the Ingress Controller, allowing external traffic to be routed through it.

Ye install karega:
- ```nginx-ingress-controller``` pod (Deployment).
- Ek ```Service type=LoadBalancer``` jo external IP expose karega.
- Ek ```ConfigMap``` for custom settings

- **Verify the Ingress Controller**:

  You can verify the Ingress Controller setup by checking the status of the ingress-nginx-controller service. Run:

  ```
    kubectl get services -o wide -w -n ingress-nginx
  ```

  This command displays the external IP address assigned to the LoadBalancer service. This IP address will serve as the entry point for external traffic directed to the Ingress Controller.

- **Update DNS**:
  - Map the domain ```myapp.example.com``` to the Load Balancer IP in your DNS provider settings.

- **Test Access**:
  - Open ```http://myapp.example.com/app1``` and ```http://myapp.example.com/app2``` in a browser.

<br>
<br>

### What is path based routing OR host based routing

Socho tumhare paas ek cluster hai jisme tumne multiple services deploy ki hain. Example:
- ek **Todo App** service.
- ek **Notes App** service.
- ek **User Profil**e service.
- ek **Analytics** service.

Ab problem kya hoti hai?
- Har ek service ki apni ClusterIP hoti hai jo cluster ke andar hi accessible hai.
- Agar tum directly external world se connect karna chahte ho to ya to har ek service ko LoadBalancer type service banana padega (jo har ek service ke liye ek alag external IP allocate karega), ya phir ek Ingress banakar ek hi external IP se sabhi services ko route kar sakte ho.

Ingress ka kaam hi ye hai ki ek single entry point (LoadBalancer IP ya domain) ke through multiple applications/services ko expose kare.
- Lekin question ye hota hai: traffic ko kis service tak bhejna hai?
- Aur ye decide karna ki kis request ko kis service tak bhejna hai, wahi kaam karte hain routing rules:

Iske liye Ingress 2 main mechanisms deta hai:
- **Host-based Routing** ‚Üí Hostname (domain) ke basis pe route hota hai.
- **Path-based Routing** ‚Üí URL path ke basis pe route hota hai.

<br>

**Path-Based Routing**:

Path-based routing me tum ek hi host/domain (ya IP) ke andar multiple URL paths define karte ho aur unko alag-alag backend services ke saath map karte ho.

Iska matlab:
- Agar request me path ```/todo``` aaya to wo todo-service tak jaye.
- Agar request me path ```/notes``` aaya to wo notes-service tak jaye.
- Agar request me path ```/profile``` aaya to wo profile-service tak jaye.

Example Scenario:

Maan lo tumhare paas ek external IP hai: ```20.55.100.25```:
- ```http://20.55.100.25/todo``` ‚Üí todo-service.
- ```http://20.55.100.25/notes``` ‚Üí notes-service.
- ```http://20.55.100.25/profile``` ‚Üí profile-service.

Ek hi IP par tumne teen alag alag microservices chala diye. Ye hi fayda hota hai ingress ka. Agar tumne simple load balancer service ke through in applications ko expose karna hota to tumko 3 alag alag load balancers banane padte, jo thik nahi hai.

<br>

**YAML (Path-based Example)**:
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: todo-ingress
spec:
  rules:
  - http:
      paths:
      - path: /todo
        pathType: Prefix
        backend:
          service:
            name: todo-service
            port:
              number: 80
      - path: /notes
        pathType: Prefix
        backend:
          service:
            name: notes-service
            port:
              number: 80
      - path: /profile
        pathType: Prefix
        backend:
          service:
            name: profile-service
            port:
              number: 80
```

<br>

**Request Flow (Path-based)**:
- User ne apne browser me request dali:
```
http://20.55.100.25/todo
```
- Request pehle jaati hai Cloud LoadBalancer (jo Ingress controller ke liye allocate hua hai).
- LoadBalancer request ko forward karta hai Ingress Controller pod ko (jaise NGINX Ingress Controller).
- Ingress controller apni rules ki table check karta hai.
  - Rule: agar path ```/todo``` se start hota hai ‚Üí backend service: todo-service.
- Ingress controller request ko todo-service ke ClusterIP pe bhej deta hai.
- Kube-proxy ya kube-proxy ka iptables rule request ko actual pod tak pahucha deta hai.
- User ko response milta hai directly todo-service ka.

<br>
<br>

**Host-Based Routing**:

Host-based routing me path important nahi hota. Yaha domain name (host) decide karta hai ki request kis service ko jaye.

Example:
- ```http://todo.example.com``` ‚Üí todo-service.
- ```http://notes.example.com``` ‚Üí notes-service.
- ```http://profile.example.com``` ‚Üí profile-service.

Example Scenario:

Maan lo tumne DNS configure kiya hua hai load balancer ki ip par:
- ```todo.example.com``` ‚Üí IP ```20.55.100.25```.
- ```notes.example.com``` ‚Üí IP ```20.55.100.25```.
- ```profile.example.com``` ‚Üí ```IP 20.55.100.25```.

Yani 3 alag domains ek hi LoadBalancer IP pe map hote hain, aur Ingress unke host header ke basis pe decide karta hai ki kaunsi service ko bhejna hai.

**YAML (Host-based Example)**:
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: todo-ingress
spec:
  rules:
  - host: todo.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: todo-service
            port:
              number: 80
  - host: notes.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: notes-service
            port:
              number: 80
  - host: profile.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: profile-service
            port:
              number: 80
```

<br>

**Request Flow (Host-based)**:
- User ne apne browser me request dali:
```
http://todo.example.com
```
- Request LoadBalancer IP pe aayi.
- LoadBalancer ne isko Ingress Controller ko bheja.
- Ingress controller HTTP request ka Host header check karega.
  - Host header: ```todo.example.com```
  - Rule: agar ```host = todo.example.com``` ‚Üí backend service: ```todo-service```.
- Request todo-service tak forward ho gayi.
- Pod ne response bhej diya user ko.

<br>

**Combined Use Case ‚Äì Host + Path**:

Real production systems me dono concepts ek saath use hote hain.

Example:
- ```shop.example.com/cart``` ‚Üí cart-service.
- ```shop.example.com/order``` ‚Üí order-service.
- ```blog.example.com/``` ‚Üí blog-service


Example Scenario:

Socho tum ek company ke paas do alag applications chala rahe ho:
- Ecommerce App (shop related services).
- Blog App (articles related services).

Aur unke andar bhi multiple microservices hain:
- Ecommerce App ‚Üí services:
  - ```/cart``` ‚Üí cart-service.
  - ```/order``` ‚Üí order-service.
  - ```/products``` ‚Üí product-service
- Blog App ‚Üí services:
  - ```/ (homepage)``` ‚Üí blog-service.
  - ```/admin``` ‚Üí blog-admin-service

Combined YAML Example:
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: combined-ingress
spec:
  rules:
  - host: shop.example.com
    http:
      paths:
      - path: /cart
        pathType: Prefix
        backend:
          service:
            name: cart-service
            port:
              number: 80
      - path: /order
        pathType: Prefix
        backend:
          service:
            name: order-service
            port:
              number: 80
      - path: /products
        pathType: Prefix
        backend:
          service:
            name: product-service
            port:
              number: 80

  - host: blog.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: blog-service
            port:
              number: 80
      - path: /admin
        pathType: Prefix
        backend:
          service:
            name: blog-admin-service
            port:
              number: 80
```

Flow Example:

Case 1: Ecommerce App (shop.example.com)
- User request ‚Üí
```
http://shop.example.com/cart
```
- Request LoadBalancer IP ‚Üí Ingress Controller.
- Ingress rule check:
  - Host = ```shop.example.com```
  - Path = ```/cart```
  - Service = cart-service.
- Request cart-service ke pod tak pahunchti hai.

<br>
<br>

### Ingress Workflow (When a user send a request to load balancer).

**Scenario Setup**:
- Tumne ek todo app deploy kiya hai Kubernetes me.
- ```todo-service``` ek ClusterIP service hai jo pods ko map karti hai.
- Tumne ek Ingress Resource banaya hai jisme ```/todo``` path ```todo-service``` pe jaata hai.
- Tumne ek Ingress Controller (NGINX) install kiya hai with Service type=LoadBalancer.
- Cloud provider (jaise Azure/AWS) ne tumhare Ingress Controller ko ek public IP allocate ki:
```
20.55.100.25
```
- Ab user isi IP ko use karke app access karega.

<br>

**Ingress Workflow**:

<br>

**Step 1: User Request Initiates**:
- User browser kholta hai aur likhta hai:
```
http://20.55.100.25/todo
```
- Ye request ek normal HTTP GET request hoti hai.

<br>

**Step 2: Request Reaches Cloud Load Balancer**:
- ```20.55.100.25``` jo IP hai, vo actually cloud provider ke Load Balancer ki IP hai.
- Request pehle external Load Balancer pe aati hai.

Example: Azure Application Gateway / AWS NLB.

<br>

**Step 3: Load Balancer to Kubernetes Node**:
- Cloud Load Balancer check karta hai ki uske backend me kaunse Kubernetes nodes associated hain.
- Ye request kisi ek healthy node pe bhej deta hai.
- Jaise maan lo cluster me 3 nodes hain ‚Üí Node1, Node2, Node3.
- Load Balancer ne request Node2 ke ek port pe bhej diya (jo NodePort automatically assign hua hai service ke liye).

<br>

**Step 4: Service (LoadBalancer Type) ‚Üí Ingress Controller Pods**:
- Cluster ke andar ```Service type=LoadBalancer``` bana tha jo Ingress Controller pods ko expose karta hai.
- Ye service NodePort/IPVS/iptables ke through request ko Ingress Controller Pod tak route karti hai.
- Ab request Ingress Controller (NGINX) pod ke paas aa gayi.

<br>

**Step 5: Ingress Controller Processing**:
- Ingress Controller apne paas stored Ingress Resource rules check karega.
- Rule kuch aisa hoga:
```
rules:
- http:
    paths:
    - path: /todo
      pathType: Prefix
      backend:
        service:
          name: todo-service
          port:
            number: 80
```
- Controller dekhta hai ki request ka path ```/todo``` hai.
- Match milta hai ‚Üí Rule ke hisaab se backend service = ```todo-service```.

<br>

**Step 6: Ingress Controller ‚Üí Backend Service (todo-service)**:
- Ingress Controller ab request ko ClusterIP service ```todo-service``` ke IP pe forward karega.
- Example:
```
todo-service ‚Üí ClusterIP: 10.96.12.45, Port: 80
```

<br>

**Step 7: Service ‚Üí Pod Selection**:
- ```todo-service``` ke backend me multiple pods run ho rahe hain (replicas). Example:
  - Pod1: 10.244.1.15:8080
  - Pod2: 10.244.2.20:8080
- Kube-proxy + iptables/IPVS decide karega ki request kis pod ko bhejna hai (round-robin ya random).
- Maan lo is request ko Pod1 mila.

<br>

**Step 8: Pod Processes the Request**:
- Ab request Pod1 (todo container) ke andar app ke HTTP server (Flask/Express/Spring etc.) pe chali gayi.
- Pod request process karega ‚Üí DB se data fetch karega (agar needed) ‚Üí response generate karega.

<br>

**Step 9: Response Returns**:
- Pod response Ingress Controller ko deta hai.
- Ingress Controller response wapas LoadBalancer ko deta hai.
- LoadBalancer response wapas client ko bhej deta hai.
- Browser me user ko todo app ka response show ho jaata hai.


<br>
<br>

### TLS Ka Basic Concept

**TLS Kya Hota Hai?**:

TLS (Transport Layer Security) ek encryption protocol hai jo ensure karta hai ki jab client (browser ya app) aur server (Ingress controller, services) ke beech data transfer ho, to data secure aur encrypted ho.

Without TLS (HTTP):
- Data plain text me travel karta hai.
- Agar koi attacker (man-in-the-middle) beech me traffic sniff kare to wo tumhara data padh lega (jaise password, credit card info).

With TLS (HTTPS):
- Data encrypted hota hai.
- Agar koi attacker packets sniff bhi kare to usko random encrypted gibberish milega.

TLS mainly 3 chiz ke liye use hota hai:
- Encryption ‚Üí Data secure rahega.
- Authentication ‚Üí Server ki identity verify hoti hai (yeh original site hai ya fake?).
- Integrity ‚Üí Data modify nahi ho sakta transmission ke beech me.

<br>

**TLS in Ingress ‚Äì Kubernetes Context**:
- Ingress me TLS ka use tab hota hai jab tum apne apps ko HTTPS ke through expose karna chahte ho instead of plain HTTP.
- Ingress controller (jaise NGINX Ingress Controller) ko tumhe ek certificate aur private key provide karni hoti hai. Ye dono ek Kubernetes Secret ke andar store hote hain.

Ingress controller (jaise NGINX Ingress Controller) ko tumhe ek certificate aur private key provide karni hoti hai. Ye dono ek Kubernetes Secret ke andar store hote hain.

High-Level Flow:
- Client browser request bhejta hai:
```
https://shop.example.com/cart
```
- Browser TLS handshake karta hai Ingress Controller ke sath (certificate check hota hai).
- Agar certificate valid hai, to secure HTTPS connection ban jata hai.
- Uske baad encrypted data request ‚Üí Ingress ‚Üí backend service ‚Üí pod tak jata hai.

**TLS Ingress YAML Example**:
- Maan lo tumhare paas ek domain hai: ```shop.example.com```.
- Aur tumne uske liye ek TLS certificate aur private key li hai (ya to Let's Encrypt, ya koi paid CA).
- Sabse pehle tum ek Kubernetes Secret banao jo certificate store kare:
```
kubectl create secret tls shop-tls-secret \
  --cert=shop.example.com.crt \
  --key=shop.example.com.key
```

Ab ye secret Ingress me reference karna hoga:
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: shop-ingress
spec:
  tls:
  - hosts:
    - shop.example.com
    secretName: shop-tls-secret   # TLS certificate secret
  rules:
  - host: shop.example.com
    http:
      paths:
      - path: /cart
        pathType: Prefix
        backend:
          service:
            name: cart-service
            port:
              number: 80
      - path: /order
        pathType: Prefix
        backend:
          service:
            name: order-service
            port:
              number: 80
```

**TLS Handshake ‚Äì Step by Step Flow**:
- Client Request:
  - User apne browser me likhta hai:
```
https://shop.example.com/cart
```

- DNS Resolution:
  - Domain ```shop.example.com``` ka DNS resolve hota hai aur uska IP LoadBalancer IP hota hai (Ingress controller ka).

- Connection Initiation:
  - Browser Ingress controller ke LoadBalancer IP par port 443 (HTTPS) par connection banata hai.
 
- TLS Handshake Process:
  - Server Hello: Ingress controller apna certificate bhejta hai client ko.
  - Certificate Verification: Browser check karta hai:
    - Kya certificate trusted CA se issue hua hai?
    - Kya certificate ka domain ```shop.example.com``` match karta hai?
    - Kya certificate abhi valid hai (expiry nahi hua)?
  - Key Exchange: Client aur server ek session key decide karte hain jisse actual communication encrypt hoga.

- Secure Communication:
  - Agar sab kuch sahi hai to ek secure TLS channel ban jata hai. Ab sabhi HTTP requests aur responses is secure tunnel ke andar encrypted rahenge.
 
- Ingress Routing:
  - Ab Ingress controller apne rules check karta hai:
    - Host = ```shop.example.com```
    - Path = ```/cart```
    - Backend = cart-service
  - Aur request secure channel ke andar pod tak forward ho jati hai.

**Benefits of TLS in Ingress**:
- Data Security: Har ek sensitive info (password, tokens, payments) encrypted hota hai.
- User Trust: Browser me ‚Äúüîí Secure‚Äù dikhata hai, warna ‚ÄúNot Secure‚Äù warning aati hai.
- Compliance: Industries (finance, healthcare) ke liye HTTPS mandatory hota hai (PCI-DSS, HIPAA).
- SEO Benefits: Google HTTPS websites ko priority deta hai ranking me.
- Multi-domain TLS: Tum Ingress me multiple hosts ke liye multiple TLS certs configure kar sakte ho.

<br>

### Types of TLS in Kubernetes

Ingress me TLS ko 2 tarike se handle kiya ja sakta hai:
- TLS Termination.
- TLS Passthrough.

**TLS Termination**:
- Ingress controller khud hi TLS terminate karta hai (certificate uske paas hota hai).
- Uske baad wo backend services ko plain HTTP pe forward kar deta hai.
- Advantage: Backend services ko TLS manage nahi karna padta, simple HTTP chalta hai.
- Disadvantage: Internal network encrypted nahi hota (lekin cluster ke andar generally safe hota hai).

**TLS Passthrough**:
- Ingress controller TLS terminate nahi karta.
- Wo directly encrypted traffic backend service ko forward kar deta hai.
- Backend service apna khud ka TLS handle karti hai.
- Advantage: End-to-end encryption maintain hota hai.
- Disadvantage: Backend services pe load zyada hota hai (har ek ko TLS samjhna padta hai).

**Note**: Most of the time TLS Termination preferred hota hai Ingress controller level par.

<br>

**TLS Termination**:
- TLS Termination ka matlab hota hai ki TLS/SSL handshake aur decryption Ingress controller (ya load balancer) ke paas hi ruk jata hai (terminate ho jata hai):
  - Client (browser / app) ‚Üí Ingress controller ke sath secure TLS handshake karega.
  - Ingress controller data ko decrypt karega.
  - Uske baad Ingress controller backend service/pod ko plain HTTP request bhejega.
  - Matlab backend services ko HTTPS/TLS samajhne ki zaroorat hi nahi hai, wo simple HTTP pe kaam karenge.

TLS Termination ka matlab hai TLS ko Ingress controller pe end karna.

**TLS Termination Flow Step by Step**:
- Maan lo ek user request bhejta hai:
```
https://todo-app.example.com
```

Step-1: Client ‚Üí Ingress (Secure Channel):
- Browser LoadBalancer IP pe port 443 (HTTPS) par connect karta hai.
- TLS handshake hota hai (Ingress apna certificate show karta hai jo tumne secret me diya tha).
- Browser aur Ingress ke beech secure channel ban jata hai.

Step-2: Ingress ‚Üí Backend (Plain HTTP):
- Ingress controller handshake complete hone ke baad encrypted request ko decrypt kar deta hai.
- Ab us request ko backend service ko simple HTTP (port 80) me bhejta hai.
- Backend service ko TLS/SSL ke baare me kuch nahi pata, wo normal HTTP request handle karta hai.

Step-3: Backend ‚Üí Ingress ‚Üí Client:
- Backend response Ingress ko plain HTTP me deta hai.
- Ingress phir us response ko encrypt karke client ko HTTPS me bhejta hai.

TLS Termination main TLS ka pura kaam sirf Ingress controller handle karta hai. Backend services free rehti hain.

**TLS Termination Example in Kubernetes**:
```
spec:
  tls:
  - hosts:
    - shop.example.com
    secretName: shop-tls-secret   # Ingress ke paas certificate hai
  rules:
  - host: shop.example.com
    http:
      paths:
      - path: /cart
        pathType: Prefix
        backend:
          service:
            name: cart-service
            port:
              number: 80   # Backend plain HTTP use kar raha hai
```
- Yaha ```cart-service``` ko TLS/HTTPS ki zaroorat nahi hai.
- Wo sirf port 80 (HTTP) par sun raha hai. Iska matlab yaha TLS termination use ho rha hai.
- TLS ka pura kaam Ingress controller (NGINX, HAProxy, Traefik, etc.) karta hai.

<br>

**TLS Passthrough Kya Hai?**:
- TLS Passthrough ka matlab hai ki Ingress controller TLS ko terminate nahi karega.
  - Matlab Ingress encrypted data ko decrypt nahi karega..
  - Wo data ko as-is (encrypted) backend service ko forward kar dega.
  - Backend service khud TLS/SSL certificate rakhegi aur handshake karegi.

Yaha end-to-end encryption hota hai ‚Üí Client ‚Üí Ingress (just forwarder) ‚Üí Backend Service (TLS terminate hota hai yaha is step pe).

**TLS Passthrough Flow ‚Äì Step by Step**:
- Maan lo ek user request bhejta hai:
```
https://todo-app.example.com
```

Step-1: Client ‚Üí Ingress:
- Browser request bhejta hai port 443 par (HTTPS).
- Normally TLS termination me Ingress controller handshake karta, but Passthrough mode me Ingress kuch nahi karta, bas traffic forward kar deta hai.

Step-2: Ingress ‚Üí Backend Service:
- Ingress encrypted TLS traffic ko backend service (jaise ```todo-service```) ke paas forward karta hai.
- Backend service khud apna certificate use karke TLS handshake complete karti hai.

Step-3: Backend Service ‚Üí Client:
- Backend service khud hi certificate dikhati hai, handshake karti hai, aur secure channel banati hai.
- Client aur backend service ke beech end-to-end TLS encryption hota hai.

**TLS Passthrough Kubernetes Example**:

Step 1: Backend Service ke paas apna TLS certificate hona chahiye:
- Maan lo tumhare paas ek service hai ```todo-service``` jo apna khud ka HTTPS (port 443) pe sun raha hai.
- Tum us pod me TLS cert aur key mount kar doge, aur wo service HTTPS pe expose hogi.

Step 2: Ingress Resource with Passthrough:
- Normal Ingress resource me ```tls:``` section likhne se TLS termination hota hai.
- Passthrough ke liye tumhe NGINX Ingress Annotations use karne padenge.

Example:
```
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: todo-ingress
  annotations:
    nginx.ingress.kubernetes.io/ssl-passthrough: "true"   # Passthrough enable
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS" # Backend service HTTPS bolna
spec:
  rules:
  - host: todo.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: todo-service
            port:
              number: 443   # Backend service is HTTPS
```

Is example me kya ho raha hai?:
- Client ‚Üí ```https://todo.example.com```.
- NGINX Ingress controller bas encrypted data ko ```todo-service:443``` pe forward karega.
- ```todo-service``` apna khud ka TLS certificate dikhayega aur handshake karega.
- Client aur service ke beech direct secure tunnel banega.

Ingress yaha middleman nahi hai, sirf forwarder hai.

<br>

**TLS Termination VS TLS Passthorugh**:

| Feature                      | **TLS Termination**                        | **TLS Passthrough**                                                   |
| ---------------------------- | ------------------------------------------ | --------------------------------------------------------------------- |
| TLS Handshake kaha hota hai? | Ingress Controller par                     | Backend Service par                                                   |
| Backend ko TLS ki zaroorat?  | ‚ùå Nahi                                     | ‚úÖ Haan                                                                |
| Backend request type         | Plain HTTP                                 | Encrypted HTTPS                                                       |
| Performance                  | Faster (Ingress ek baar decrypt karta hai) | Thoda slow (har pod TLS handle karega)                                |
| Use Case                     | Normal apps, microservices                 | Strict security, end-to-end encryption (finance, healthcare, banking) |


<br>
<br>

### More about ingress

In my greenlit project there is an ingress implementation which yaml's looks like below. In the bwloe yaml you can see there no host mentioned. Let's understand it.

```
apiVersion: v1
kind: Namespace
metadata:
  creationTimestamp: null
  name: shipping-service
spec: {}
status: {}
---
apiVersion: v1
data:
  .dockerconfigjson: ewoJImF1dGhzIjogewoJCSJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOiB7CgkJCSJhdXRoIjogImNIVnVaV1YwTVRwd2EzWXhNVFJBVWpreE1ERTVPVGs9IgoJCX0sCgkJInJlZ2lzdHJ5ZGV2YXVlYXN0MDAxLmF6dXJlY3IuaW8iOiB7CgkJCSJhdXRoIjogIk9EVmtOV1V6TlRrdE5XVTBPQzAwWmpBMUxXSmlPREl0WmpCbU1ERTFOekV5TnpCa09tUmhZamhSZm5kc2NtVldjVTAxVjNnNVpTNW5WeTE0WlRaRmIwSXhVRWR0WVhOWGQyeGlVVFk9IgoJCX0KCX0KfQ==
kind: Secret
metadata:
  creationTimestamp: null
  name: registry-secret-new
  namespace: shipping-service
type: kubernetes.io/dockerconfigjson
---
apiVersion: apps/v1
kind: Deployment
metadata:
 namespace: shipping-service
 name: shipping-service
 labels: 
  owner: Aquib
spec:
 replicas: 1
 selector:
  matchLabels:
   app : shipping-service
 template:
  metadata:
   labels:
    app : shipping-service
  spec:
   containers:
   - name: shipping-service
     image: registrydevaueast001.azurecr.io/shippingservice:#(dockertag)#
     imagePullPolicy: Always
     ports:
     - containerPort: 80
     resources:
      # limits:
      #  memory: 500Mi
      #  cpu: 30m
      requests:
        memory: 500Mi
        cpu: 30m
    #  Update the Key vault credentials here
     env:
      - name: KVClientId
        value: "ff7e2427-18ef-4373-a0ea-f9d60536e3c1"
      - name: KVClientSecret
        value: "ra-bu-~1pp.LStD_5foY3N76oXm6s5gZyA"
      - name: KVEndpoint
        value: "https://shipping-vault-dev-001.vault.azure.net/"
      - name: ASPNETCORE_ENVIRONMENT
        value: "Dev001"  
   imagePullSecrets:
      - name: registry-secret-new
---
apiVersion: v1
kind: Service
metadata:
 namespace: shipping-service
 name: shipping-service-svc
 labels:
  kind : service
spec:
 type: ClusterIP
 selector:
    app : shipping-service
 ports:
 - protocol: TCP
   port: 80
   targetPort: 80
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  namespace: shipping-service
  name: shippng-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: shipping-service
  minReplicas: 1
  maxReplicas: 4
  metrics:
  - type: Resource
    resource:
      name: memory
      target:
        averageUtilization: 80
        type: Utilization
  - type: Resource
    resource:
      name: cpu
      target:
        averageUtilization: 80
        type: Utilization
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: shipping-service-ingress
  namespace: shipping-service
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  ingressClassName: nginx
  rules:
  - http:
      paths:
      - path: /shipping(/|$)(.*)
        pathType: ImplementationSpecific
        backend:
          service:
            name: shipping-service-svc
            port:
              number: 80
```

In this YAML configuration, the Ingress resource does not specify a ```host``` field, which makes it a catch-all configuration. This means that the Ingress rule will respond to requests sent to any hostname, as long as the request path matches the ```path``` specified. This is typically used in scenarios where the application doesn‚Äôt require a specific hostname or is designed to respond to requests on any hostname, as is often the case in development environments or internal services that don‚Äôt need external DNS entries.

**Explanation of Key Parts**:

Let‚Äôs break down the critical elements in this Ingress configuration to understand how it functions without a specified host.

- **Path-Based Routing Without Host**

  ```
    rules:
    - http:
        paths:
        - path: /shipping(/|$)(.*)
          pathType: ImplementationSpecific
          backend:
            service:
              name: shipping-service-svc
              port:
                number: 80
  ```

  Explaination:

  - **path**: ```/shipping(/|$)(.*):``` This path uses a regular expression-like syntax to match any URL path that starts with ```/shipping``` or has ```/shipping/``` as a prefix. For example, requests to ```/shipping```, ```/shipping/order```, and ```/shipping/status``` would match this rule. The use of (.*) at the end allows it to match any characters that follow /shipping.
 
  - **pathType**: ```ImplementationSpecific```: This allows the Ingress Controller (in this case, the NGINX Ingress Controller as specified by ```ingressClassName: nginx```) to determine how to handle path matching. NGINX typically interprets this in a flexible way, allowing regex or prefix-based matching as defined by the ```path```.
 
  - **Backend Service**: Requests that match the path rule are forwarded to the shipping-service-svc service on port 80, which routes traffic to the shipping-service Pods.

- **No Host Specification**:

  - Since the host field is omitted, this Ingress will catch all requests that match the path rule regardless of the hostname. In practice, this means it can respond to requests made to any domain or IP pointing to the Ingress Controller.
 
  - This is useful when you want to simplify routing rules or when the application doesn‚Äôt need to differentiate requests based on the hostname.

- **How It Works in Your Scenario with Azure AKS**:

  Assuming that you have:
  - An AKS cluster with the NGINX Ingress Controller installed.
  - A public IP assigned to the Ingress Controller via an Azure Load Balancer.

  Here‚Äôs how this Ingress will work when a user makes a request:

  - **Request to Load Balancer IP**: When a user accesses the Load Balancer‚Äôs IP (e.g., ```http://<LoadBalancer-IP>/shipping/orders```), the request is directed to the Ingress Controller within AKS.
 
  - **Ingress Controller Checks Path Rules**: The Ingress Controller checks if any Ingress resource has a path rule that matches ```/shipping/orders```. Since this configuration has a path rule of ```/shipping(/|$)(.*)```, this request matches and is accepted.
 
  - **Routing to Service**: The Ingress Controller then forwards the request to ```shipping-service-svc``` on port 80.
 
  - **Service to Pods**: The ```shipping-service-svc``` service load-balances the request to one of the available ```shipping-service Pods```, which processes the request and returns the response.
 
  - **Response**: The response travels back through the Service, Ingress Controller, and Load Balancer to the user.
 
- **When to Use This Configuration**

  This kind of hostless Ingress configuration is commonly used when:
  - The service should respond to requests on any hostname.
  - The service is internal or accessed only through IP, rather than a specific domain.
  - You‚Äôre setting up a simple routing rule in a development or testing environment.
 
  In production, it‚Äôs often a best practice to specify a host to improve security, control, and organization (e.g., to separate different applications by domain). However, omitting the host can simplify things for internal or non-production services.

<br>
<br>
<hr>

## Example (Lab):

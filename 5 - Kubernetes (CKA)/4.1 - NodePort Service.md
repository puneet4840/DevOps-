# NodePort Service

- **NodePort**

  A NodePort Service allows you to access an application running inside the Kubernetes cluster using Ip Address of any worker node and a fixed port (called the NodePort). This port remains same across all the worker nodes, making it easy to access the app from outside the cluster.

  ```NodePort service के through हम application को worker node की Ip address और उसके एक port जिसको हम NodePort कहते हैं, उसपर access करते हैं.```

  NodePort service is good for testing and simple external access, but not for large-scale production. If you want to test your app locally and want to see it from your browser so you can use NodePort service.

  **What problem does NodePort solves?**

  Imagine you have an app running in Kubernetes, like a small website. By default, Kubernetes applications are only accessible inside the cluster. But sometimes, we want to make these apps available outside the cluster. A NodePort is a solution for this because it allows access from outside by opening a port called NodePort on each worker node.

  **How does NodePort works?**

    - When you create a NodePort service, kubernetes assigns a port from a specific range (30000 - 32767) to your service.
    - This port, called **NodePort** is opened on every node in the cluster, allowing traffic from outside the cluster to reach the service.
    - Traffic that comes to a node's IP address on this NodePort is forwarded to the pods in the cluster.

  **Example (LAB): Deploying a Simple Web Application Using NodePort**

  Let's go through a simple example to understand how to set up a NodePort service and access an application.

    - **Create a deployment with 3 replicas:**

        Create the deployment YAML file named nginx-deployment.yaml:

        ```
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: my-nginx-deployment
          spec:
            replicas: 3                       # Number of replicas
            selector:
              matchLabels:
                app: my-nginx-app
            template:  
              metadata:
                labels:
                  app: my-nginx-app           # Label to identify pods
              spec:
                containers:
                - name: nginx
                  image: nginx:latest          # Using the latest NGINX image
                  ports:
                  - containerPort: 8080        # Port where NGINX listens inside the pod

        ```

        In this configuration:
          - replicas: 3 tells Kubernetes to keep 3 replicas (3 pods) running.
          - app: my-nginx-app is a label that we’ll use to link this Deployment to a Service.

    - **Deploy the Deployment**:
      
        Run the following command in your terminal to create the Deployment:
      
        ```kubectl apply -f nginx-deployment.yaml```

    - **Verify the Deployment**:

        Use this command to check if the pods are running:

        ```kubectl get deployments```
        ```kubectl get pods```

    - **Create the NodePort Service**

      Now, let’s expose the Deployment with a NodePort Service. This will open a specific port on each node in your cluster, allowing access to the NGINX web server from outside.

      Create a ```nginx-service.yaml``` YAML File for the NodePort Service
      
        ```
          apiVersion: v1
          kind: Service
          metadata:
            name: my-nginx-service
          spec:
            type: NodePort                       # NodePort to expose it outside the cluster
            selector:
              app: my-nginx-app                  # Selects the pods with this label
            ports:
            - protocol: TCP
              port: 80                         # Internal service port
              targetPort: 8080                 # Port where the pod’s container listens
              nodePort: 30008                  # External port (must be between 30000 and 32767)

        ```

        Explanation:

        - ```type: NodePort``` tells Kubernetes to create a NodePort Service.
        - ```port: 80``` is the internal port for the Service.
        - ```targetPort: 8080``` is the port on the pod’s container (where NGINX is listening).
        - ```nodePort: 30008``` is the external port that Kubernetes will open on each node to access the app from outside.

    - **Deploy the Service**:

      Run the following command to create the NodePort Service:

      ```kubectl apply -f nginx-service.yaml```

    - **Verify the Service**:

      ```kubectl get services```

      You should see ```my-nginx-service``` with Type as ```NodePort```, and it should list the nodePort as ```30008```.

    - **Access the Application**:

      Now, we can access the NGINX web server from outside the cluster.

      - Get the Node’s IP Address:

        ```kubectl get nodes -o wide```

        Let’s say the IP address of one of your nodes is ```10.0.0.5```.

        You can access the NGINX web server by navigating to the following URL in a browser or using curl:

        ```curl http://10.0.0.5:30008```

        This will display the default NGINX welcome page if everything is set up correctly.


    - **How Kubernetes manage NodePort traffic**

      When you send a request to ```http://10.0.0.5:30008```, here’s how Kubernetes handles it:

      - Node Port Mapping: The NodePort Service listens on port 30008 of every node in the cluster.
      - Routing to Pod: Kubernetes receives the request on port 30008 and forwards it to the nginx pod running on port 8080 (using the ClusterIP service internally).
      - Response Handling: The pod processes the request and sends the response back through the same route.


**How does NodePort works?**

NodePort bss ek port open karta hai Worker node ke uper. Lekin cluster main node port ke naam se ek cluster ip ki service ban jati hai. Traffic jo hota hai pod ke uper vo cluster ip se hoke aata hai.


<br>

### How traffic reaches to pod in NodePort type of service

**1. Client Request Initiation (External User Se Request)**

Jab koi external user (jaise browser, Postman ya curl) Kubernetes cluster ke bahar se kisi application ko access karta hai, to usko cluster ke IP address (ya hostname) aur NodePort ki jarurat hoti hai.

Example:

Cluster mein ek NodePort service hai jo NodePort: 30080 pe run kar rahi hai. User call karta hai:
```
http://<NodeIP>:30080
```

Yaha <NodeIP> kisi bhi Kubernetes node ka IP ho sakta hai.


**2. Request Reaches the Node (Koi bhi Node)**

Kubernetes ke har Node ke IP par woh port (30080) open hota hai. Iska matlab:
- Agar cluster mein 3 nodes hain, to teeno par woh NodePort khula rahega.

Is wajah se user chahe kisi bhi node ke IP se request kare, NodePort us request ko receive karega.

**3. kube-proxy Ka Role (Traffic ko Forward Karne Mein)**

NodePort ke piche ka magic karta hai ```kube-proxy```, jo har node par chalta hai.

Kube-proxy Linux ke networking tool (iptables / IPVS) ka use karke ek ruleset banata hai.

Ye rules kahte hain:
```
Agar port 30080 pe koi traffic aaye,
to isse service X ke backend pods me se kisi ek ko forward karo.
```

Yani, kube-proxy NodePort se traffic ko cluster ip service tak pahuchata hai fir cluster ip service se pod tak traffic pahunchta hai.

**4. ClusterIP Se Backend Pods**

NodePort service internally ek ClusterIP service ko represent karta hai. ClusterIP service ek label selector ke basis pe backend pods ko identify karti hai (deployment ke through banaye gaye pods).

Ab ClusterIP service ek load balancer ki tarah kaam karti hai — ye decide karti hai ki incoming request kis pod ko forward ki jaye.


<br>

### Pod Tak Traffic Ka Flow Summarized:

```
External Client
    ↓
Node IP (koi bhi)
    ↓
NodePort (e.g., 30080)
    ↓
kube-proxy (iptables/IPVS)
    ↓
ClusterIP service
    ↓
Matching Pods (via selector)
```

<br>

**Example: NodePort Use Case in Real World**

Tumhare paas ek 3-node cluster hai:
| Node Name | Node IP      |
| --------- | ------------ |
| node1     | 192.168.1.10 |
| node2     | 192.168.1.11 |
| node3     | 192.168.1.12 |

Tumhare pod node2 pe chal raha hai, par service har node pe 30080 port expose karega. Agar tum 192.168.1.10:30080 bhi hit karoge, to kube-proxy is request ko node2 ke pod tak pahucha dega.
